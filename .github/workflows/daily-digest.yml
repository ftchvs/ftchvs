name: Daily Multi-Section Digest

on:
  schedule:
    # Run daily at 00:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: write  # Required to push changes to README

jobs:
  update-digest:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create archive directory
        run: |
          mkdir -p archive

      - name: Fetch GitHub stats
        id: fetch_stats
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_USERNAME: ftchvs
          PAT_PRIVATE: ${{ secrets.PAT_PRIVATE }}
        run: |
          python3 scripts/log_stats.py > /tmp/github_stats.json 2>/tmp/github_stats_error.log || echo '{"date":"","markdown":"## ðŸ“Š Daily Dev Activity\n\n*Error fetching stats.*\n","stats":{}}' > /tmp/github_stats.json

      - name: Fetch content and generate summaries
        id: fetch_content
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          python3 scripts/summarize_content.py > /tmp/content_summary.json 2>/tmp/content_summary_error.log || echo '{"date":"","error":"Failed to fetch content","ai_news":{"markdown":"","stories":[],"summary":""},"business_news":{"markdown":"","stories":[],"summary":""},"tech_news":{"markdown":"","stories":[],"summary":""},"podcasts":{"markdown":"","podcasts":[],"summary":""},"motivation_quotes":{"markdown":"","items":[],"summary":""},"wise_knowledge":{"markdown":"","items":[],"summary":""}}' > /tmp/content_summary.json

      - name: Fetch podcast summaries
        id: fetch_podcasts
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        continue-on-error: true
        run: |
          python3 scripts/summarize_podcasts.py > /tmp/podcasts_summary.json 2>/tmp/podcasts_summary_error.log || echo '{"date":"","markdown":"","podcasts":[]}' > /tmp/podcasts_summary.json

      - name: Merge podcast content into main summary
        run: |
          if [ -f /tmp/podcasts_summary.json ]; then
            python3 << 'EOF'
            import json
            import sys
            
            try:
                with open('/tmp/content_summary.json', 'r') as f:
                    content = json.load(f)
                
                with open('/tmp/podcasts_summary.json', 'r') as f:
                    podcasts = json.load(f)
                
                if 'markdown' in podcasts and podcasts['markdown']:
                    content['podcasts'] = {
                        'markdown': podcasts['markdown'],
                        'podcasts': podcasts.get('podcasts', []),
                        'summary': podcasts.get('summary', '')
                    }
                
                with open('/tmp/content_summary.json', 'w') as f:
                    json.dump(content, f, indent=2, ensure_ascii=False)
            except Exception as e:
                print(f"Error merging podcasts: {e}", file=sys.stderr)
            EOF
          fi

      - name: Copy archive files
        run: |
          if [ -f archive/*-digest.json ]; then
            cp archive/*-digest.json /tmp/ 2>/dev/null || true
          fi

      - name: Update README
        id: update_readme
        env:
          STATS_JSON: /tmp/github_stats.json
          CONTENT_JSON: /tmp/content_summary.json
          README_PATH: README.md
        run: |
          python3 scripts/update_readme.py

      - name: Check for changes
        id: verify_changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "changed=true" >> $GITHUB_OUTPUT
          else
            echo "changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.verify_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add README.md logs/ archive/
          git commit -m "ðŸ“Š Daily digest update: $(date +'%Y-%m-%d')"
          git push

      - name: Send email notification
        if: env.SENDGRID_API_KEY != '' && env.NOTIFY_EMAIL != ''
        continue-on-error: true
        env:
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          SENDGRID_FROM_EMAIL: ${{ secrets.SENDGRID_FROM_EMAIL }}
          NOTIFY_EMAIL: ${{ secrets.NOTIFY_EMAIL }}
          NOTIFY_TYPE: email
          STATS_JSON: /tmp/github_stats.json
          AI_JSON: /tmp/content_summary.json
        run: |
          python3 scripts/send_notification.py

      - name: Send SMS notification
        if: env.TWILIO_ACCOUNT_SID != '' && env.NOTIFY_PHONE != ''
        continue-on-error: true
        env:
          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}
          TWILIO_AUTH_TOKEN: ${{ secrets.TWILIO_AUTH_TOKEN }}
          TWILIO_PHONE_NUMBER: ${{ secrets.TWILIO_PHONE_NUMBER }}
          NOTIFY_PHONE: ${{ secrets.NOTIFY_PHONE }}
          NOTIFY_TYPE: sms
          STATS_JSON: /tmp/github_stats.json
          AI_JSON: /tmp/content_summary.json
        run: |
          python3 scripts/send_notification.py

      - name: Archive logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: digest-logs
          path: |
            /tmp/github_stats.json
            /tmp/content_summary.json
            logs/*.md
            archive/*.json
          retention-days: 7

